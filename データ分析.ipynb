{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCVとDlibを用いた画像認識 ｰデータ分析ｰ\n",
    "\n",
    "以下のコードを参考に、画像認識で得たデータの活用を理解してください。\n",
    "各教材を解きながら、データの加工や可視化、データ分析の流れを学んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人通りの変化をグラフで確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "print(\"分析を開始します\")\n",
    "\n",
    "# 動画ファイルの読み込み\n",
    "cap = cv2.VideoCapture(\"vtest.avi\")\n",
    "\n",
    "# 動画のフレームレート（FPS）を取得\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# HOG（Histogram of Oriented Gradients）人物検出器の設定\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "hogParams = {\n",
    "    'winStride': (4, 4),    # 検出ウィンドウの移動ステップ\n",
    "    'padding': (8, 8),      # 検出ウィンドウの周りのパディング\n",
    "    'scale': 1.05,          # 画像ピラミッドのスケール\n",
    "    'hitThreshold': 0,      # 検出閾値\n",
    "    'finalThreshold': 5     # 重複検出のフィルタリング閾値\n",
    "}\n",
    "\n",
    "num = 0  # フレームカウンター\n",
    "# 結果を格納するためのデータフレームを初期化\n",
    "list_df = pd.DataFrame(columns=['time', 'people'])\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()  # フレームを1つ読み込む\n",
    "    if ret:\n",
    "        if (num % 10 == 0):  # 10フレームごとに処理\n",
    "            # グレースケールに変換（人物検出の精度向上のため）\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # 人物検出を実行\n",
    "            human, r = hog.detectMultiScale(gray, **hogParams)\n",
    "            \n",
    "            if (len(human) > 0):  # 人物が検出された場合\n",
    "                for (x, y, w, h) in human:\n",
    "                    # 検出された人物を白い矩形で囲む\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n",
    "            \n",
    "            # 時間と検出された人数をデータフレームに追加\n",
    "            tmp_se = pd.Series([num/fps, len(human)], index=list_df.columns)\n",
    "            list_df = list_df.append(tmp_se, ignore_index=True)\n",
    "            \n",
    "            # 検出結果を表示\n",
    "            cv2.imshow('frame', frame)\n",
    "            # 'q'キーが押されたらループを終了\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    else:\n",
    "        break  # 動画の終わりに達したらループを終了\n",
    "    \n",
    "    num += 1  # フレームカウンターを増加\n",
    "\n",
    "# リソースの解放\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"分析を終了しました\")\n",
    "# この時点で list_df には時間と検出された人数のデータが格納されています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グラフプロット "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib ライブラリをインポート\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# list_dfは既に存在すると仮定します\n",
    "\n",
    "# 時間と人数のグラフを作成\n",
    "plt.plot(list_df[\"time\"], list_df[\"people\"])\n",
    "\n",
    "# X軸のラベルを設定\n",
    "plt.xlabel('time(sec.)')\n",
    "\n",
    "# Y軸のラベルを設定\n",
    "plt.ylabel('population')\n",
    "\n",
    "# Y軸の範囲を0から8に設定\n",
    "plt.ylim(0, 8)\n",
    "\n",
    "# グラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PELTアルゴリズムを用いた変化点検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruptures as rpt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# list_dfは既に存在すると仮定します\n",
    "\n",
    "# 人数データを抽出\n",
    "signal = list_df['people'].values\n",
    "\n",
    "# モデルの選択（\"l1\", \"l2\", \"rbf\"など）\n",
    "model = \"rbf\"\n",
    "\n",
    "# PELTアルゴリズムを使用して変化点検出を実行\n",
    "algo = rpt.Pelt(model=model).fit(signal)\n",
    "\n",
    "# ペナルティ値の設定（変化点の数を調整）\n",
    "penalty = 3  # 必要に応じて調整\n",
    "\n",
    "# 変化点のインデックスを取得\n",
    "result = algo.predict(pen=penalty)\n",
    "\n",
    "# 検出された変化点を表示\n",
    "print(\"検出された変化点のインデックス:\", result)\n",
    "\n",
    "# 時間と人数のプロットを作成し、変化点を表示\n",
    "plt.plot(list_df['time'], signal, label='population')\n",
    "\n",
    "# 検出された変化点に垂直線を引く\n",
    "for cp in result[:-1]:  # 最後のポイントは信号の終わりなので除外\n",
    "    plt.axvline(x=list_df['time'].iloc[cp], color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('time(sec.)')\n",
    "plt.ylabel('population')\n",
    "# Y軸の範囲を0から8に設定\n",
    "plt.ylim(0, 8)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移動平均を計算することでノイズの影響を除去する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def moving_average(x, y):\n",
    "    y_conv = np.convolve(y, np.ones(5)/float(5), mode='valid')\n",
    "    x_dat = np.linspace(np.min(x), np.max(x), np.size(y_conv))\n",
    "    return x_dat, y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_df[\"time\"], list_df[\"people\"], label=\"raw\")\n",
    "ma_x, ma_y = moving_average(list_df[\"time\"], list_df[\"people\"])\n",
    "plt.plot(ma_x,ma_y, label=\"average\")\n",
    "plt.xlabel('time(sec.)')\n",
    "plt.ylabel('population')\n",
    "plt.ylim(0,8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 到達度確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課題1：Webカメラの読み込みと人物検出\n",
    "* Webカメラを読み込み、OpenCVを用いて人物検出を行い、検出した人数を時間とともに記録してみよう。\n",
    "* Dlibを用いて動画内の顔を検出を行い、検出した顔数を時間とともに記録してみよう。\n",
    "     \n",
    "課題2：人数データの可視化\n",
    "* 課題1で取得した人数および顔数データを用いて、時間に対する値の変化をグラフで表示してみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 応用課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 変化点検出アルゴリズムの比較\n",
    "    * 目的：PELTアルゴリズム以外の変化点検出アルゴリズム（例えば、BinsegやBottomUpなど）を試し、検出結果を比較する。\n",
    "* 人流データの統計分析\n",
    "    * 目的：取得したデータからピーク時の人数や平均人数などの統計情報を算出し、時間帯による人流の傾向を分析する。\n",
    "* 異なる環境でのデータ分析\n",
    "    * 目的：別の動画データ（例えば、夜間の映像や異なる場所の映像）を用いて同様の分析を行い、環境の違いによる人流の変化を比較する。\n",
    "* 集中度の評価\n",
    "    * 目的：検出した顔の向きデータから、ユーザーが画面に対してどの程度集中しているかを分析し、一定時間以上画面から目を逸らしている場合に警告を表示するシステムを構築する。\n",
    "* 顔向きと行動パターンの関連性\n",
    "    * 目的：顔の向きと他の行動（例：キーボード入力やマウス操作）との関連性を調査し、生産性の指標として活用する方法を検討する。\n",
    "* 顔表情の変化検出\n",
    "    * 目的：Dlibや他のライブラリを用いて、動画内の人物の表情を解析し、感情の変化を時系列で可視化する。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
